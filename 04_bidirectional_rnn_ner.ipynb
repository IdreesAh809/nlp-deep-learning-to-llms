{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a8bcb9-c951-452a-b7f2-ac57decf85ba",
   "metadata": {},
   "source": [
    "# Bidirectional RNN for Named Entity Recognition (NER)\n",
    "\n",
    "### Introduction\n",
    "In standard RNNs, information flows **only in one direction** (past → future).  \n",
    "But in many NLP tasks (like NER), the meaning of a word depends on both its **left context** and **right context**.\n",
    "\n",
    "**Example:**  \n",
    "- In \"Apple is looking at buying a U.K. startup\",  \n",
    "  - \"Apple\" is an organization, not a fruit — we know this by looking at the words *after* it.  \n",
    "\n",
    "**Bidirectional RNNs** process the sequence **forward and backward**, then combine both outputs.  \n",
    "This helps the model capture **full context** around each word.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "We’ll use the **NER dataset**: [Kaggle NER Dataset](https://www.kaggle.com/datasets/namanj27/ner-dataset?).  \n",
    "It contains:  \n",
    "- `Word` → actual word in the sentence  \n",
    "- `POS` → part-of-speech tag  \n",
    "- `Tag` → NER label (e.g., `B-geo`, `B-org`, `O`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef79f70c-2b3b-4b62-9695-4db82f4522b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Step 1: Import libraries\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f174f6b-ec68-48c7-a7b4-d8ea3fa6fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IDREES AHMAD\\AppData\\Local\\Temp\\ipykernel_29496\\657636566.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.read_csv(\"dataset/ner_datasetreference.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 2: Load small sample dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"dataset/ner_datasetreference.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "df = df.sample(n=2000, random_state=42)  # take small sample for faster training\n",
    "\n",
    "# Unique words and tags\n",
    "words = list(set(df[\"Word\"].values))\n",
    "tags = list(set(df[\"Tag\"].values))\n",
    "n_words, n_tags = len(words), len(tags)\n",
    "\n",
    "# Mapping\n",
    "word2idx = {w:i+2 for i,w in enumerate(words)}\n",
    "word2idx[\"PAD\"], word2idx[\"UNK\"] = 0, 1\n",
    "tag2idx = {t:i for i,t in enumerate(tags)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ad1927-3f0c-45ec-b232-d2dae59219b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IDREES AHMAD\\AppData\\Local\\Temp\\ipykernel_29496\\1226077345.py:5: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sentences = df.groupby(\"Sentence #\").apply(lambda s: [(w,t) for w,t in zip(s[\"Word\"],s[\"Tag\"])]).tolist()\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 3: Prepare sequences\n",
    "# -------------------------------\n",
    "MAX_LEN = 50\n",
    "sentences = df.groupby(\"Sentence #\").apply(lambda s: [(w,t) for w,t in zip(s[\"Word\"],s[\"Tag\"])]).tolist()\n",
    "\n",
    "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w,t in s] for s in sentences]\n",
    "X = pad_sequences(X, maxlen=MAX_LEN, padding='post', value=word2idx[\"PAD\"])\n",
    "\n",
    "y = [[tag2idx[t] for w,t in s] for s in sentences]\n",
    "y = pad_sequences(y, maxlen=MAX_LEN, padding='post', value=tag2idx[\"O\"])\n",
    "y = np.array([to_categorical(seq, num_classes=n_tags) for seq in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a66fb7-0b90-44ef-acce-6367c077e3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">63,616</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">46,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,313</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m63,616\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m46,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m13\u001b[0m)              │           \u001b[38;5;34m1,313\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,929</span> (433.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,929\u001b[0m (433.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,929</span> (433.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,929\u001b[0m (433.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 4: Train/Test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Build Bidirectional LSTM\n",
    "# -------------------------------\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=n_words+2, output_dim=64, input_length=MAX_LEN, mask_zero=True),\n",
    "    Bidirectional(LSTM(50, return_sequences=True)),\n",
    "    TimeDistributed(Dense(n_tags, activation=\"softmax\"))\n",
    "])\n",
    "model.build(input_shape=(None, MAX_LEN))\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a8a4ab-efcd-4e91-8be6-3110f5bcb3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 110ms/step - accuracy: 0.9761 - loss: 2.3806 - val_accuracy: 0.9968 - val_loss: 1.9962\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9967 - loss: 1.3368 - val_accuracy: 0.9973 - val_loss: 1.0578\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9969 - loss: 0.6613 - val_accuracy: 0.9975 - val_loss: 0.8204\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.9972 - loss: 0.4849 - val_accuracy: 0.9974 - val_loss: 0.7626\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.9974 - loss: 0.4483 - val_accuracy: 0.9974 - val_loss: 0.7401\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 6: Train the model\n",
    "# -------------------------------\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, batch_size=32, epochs=5, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "313affa9-1506-4739-ab02-9ac2f72c6f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 376ms/step\n",
      "Sentence: ['Palestinian', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month']\n",
      "Predicted: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual   : ['B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Sentence: ['genocide', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month']\n",
      "Predicted: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual   : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Sentence: ['Hungarian', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month']\n",
      "Predicted: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual   : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Sentence: ['advisors', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month']\n",
      "Predicted: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual   : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Sentence: ['wounding', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month', 'month']\n",
      "Predicted: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual   : ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to tag names (only first 5 sentences for simplicity)\n",
    "for i in range(5):\n",
    "    pred_tags = [list(tag2idx.keys())[np.argmax(p)] for p in y_pred[i]]\n",
    "    true_tags = [list(tag2idx.keys())[np.argmax(p)] for p in y_test[i]]\n",
    "    # Only show non-PAD words\n",
    "    sentence_words = [list(word2idx.keys())[X_test[i][j]] if X_test[i][j] in word2idx.values() else \"UNK\" for j in range(MAX_LEN)]\n",
    "    print(\"Sentence:\", sentence_words[:10])\n",
    "    print(\"Predicted:\", pred_tags[:10])\n",
    "    print(\"Actual   :\", true_tags[:10])\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec4d0f-59fc-4c1b-b148-801886c8c486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
